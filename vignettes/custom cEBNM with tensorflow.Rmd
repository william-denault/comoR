---
title: "custom como with tensorflow "
author: "William R.P. Denault"
date: "2024-02-29"
output: html_document
---

```{r setup, include=FALSE}
rm(list=ls())
library(keras)
library(comoR)
library(nnet)
library(tensorflow)
knitr::opts_chunk$set(echo = TRUE)
tf$compat$v1$logging$set_verbosity(tf$compat$v1$logging$ERROR)
```

##  simulate data

```{r cars}

devtools::load_all(".")
set.seed(1)
y <-runif(2000,min=-0.5, max=2.5)
X = cbind(y)
xtrue = 0*y
for (i in 1:length(xtrue)){

  if ( (    y[i] <.5 & y[i] >.0 ) | (y[i] >1.5 & y[i] <2) ){
    xtrue[i] = 0
  }else{
    xtrue[i]= rnorm(1,sd=0.5+ 2*abs(sin( pi*y[i])))
  }


}
plot (y,xtrue, main="true underlying effect",
       col =ifelse(xtrue==0, 3,4))
legend('topleft',c( expression(x[true] == 0) ,expression(x[true] != 0)),col=c(3,4),pch=1)
x = xtrue + rnorm(length(xtrue), sd=1)
plot (y,x, main="observed estimates",
       col =ifelse(xtrue==0, 3,4))
legend('topleft',c( expression(x[true] == 0) ,expression(x[true] != 0)),col=c(3,4),pch=1)
s= rep(1,length(x))
Z <- matrix( 1, nrow=length(x), ncol=1)


```

## prepare como object

```{r}
#start by defining the como parameter using mixture of exponential priors and a neural net regressor
param_como = list(max_class= 10,
                  mnreg_type="keras",
                  prior ='mix_norm'# "mix_exp"
                  )
data <- comoR:::como_prep_data (betahat=x,
                                 se=s, X=X,
                                 Z =Z )
```



##define neural net architecture using tensorflow


```{r} 
num_classes <- length( autoselect_scales_mix_exp(data$betahat, data$se,10))

#define the nnet paramet using Keras syntax
param_nnet =keras_model_sequential() %>%
  layer_dense(units = 64,
              activation = 'relu',
              input_shape = c(1)) %>%
  layer_dense(units = 64,
              activation = 'relu' ) %>% 
  layer_dense(units = 32,
              activation = 'relu' ) %>%
  layer_dense(units = 16,
              activation = 'relu' ) %>%
  layer_dense(units = num_classes,#important to have the same number of units as the number of classes
              activation = 'softmax')
```

### fit model

```{r message=FALSE, warning=FALSE, include=FALSE}
fit_como  <- rlang::exec( "data_initialize_como", !!! param_como ,
                          data= data,
                          param_nnet= param_nnet) # initialize the model from the data
fit =fit_como

#fit$data_loglik <- compute_data_loglikelihood(fit, data)
#hist(fit$data_loglik)

fit_como <- comoR:::fit.como ( fit_como, data, max_iter = 40 )
fit =fit_como


```

## check performances


```{r}

plot(y ,fit_como$post_assignment[,1],   col =ifelse((    y  <.5 & y  >.0 ) | (y  >1.5 & y  <2) , 3,4), main= "estimated mixture proportions for H0")
legend('topleft',c( expression(x[true] == 0) ,expression(x[true] != 0)),col=c(3,4),pch=1)

 



plot(y , fit_como$post_assignment[,7],  col =ifelse((    y  <.5 & y  >.0 ) | (y  >1.5 & y  <2) ,3,4), main= "estimated mixture proportions 7th component")
legend('topleft',c( expression(x[true] == 0) ,expression(x[true] != 0)),col=c(3,4),pch=1)

est <- comoR:::post_mean_sd (fit,data)
  

ash_res <- ashr::ash(x, s )

 

plot(x=ash_res$result$PosteriorMean,
     y=est$mean,  
     col =ifelse(xtrue==0, 3,4),
     main='comparison of ebnm vs cebnm',xlab='ebnm',ylab='cebnm',
     xlim=c(-5,5),ylim=c(-5,5))
legend('topleft',c( expression(x[true] == 0) ,expression(x[true] != 0)),col=c(3,4),pch=1)

abline(h=0)
abline(a=0,b=1)

rmse = function(x,y){
  sqrt(mean ((x-y)^2))
}
rmse(ash_res$result$PosteriorMean, xtrue)

rmse(est$mean, xtrue )

```
```{r}
 plot(y,x , ylim=c(-7,7))
points(y,xtrue, col='lightgreen')
legend('topleft',c( expression(x[true] ) ,expression(x[obs]  )),col=c('lightgreen',"black"),pch=1)


  plot(y,est$mean ,ylab="" ,ylim=c(-7,7))
points(y,xtrue, col='lightgreen')
legend('topleft', 
       legend = c(expression(x[true]  ), expression(p(x ~ "|" ~ x[obs] * "," ~ y))), 
       col = c('lightgreen', 'black'), 
       pch = 1)

```

